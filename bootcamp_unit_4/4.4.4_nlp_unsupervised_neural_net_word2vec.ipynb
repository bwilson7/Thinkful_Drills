{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import sklearn\n",
    "import spacy\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "from nltk.corpus import gutenberg, stopwords\n",
    "import gensim\n",
    "from gensim.models import word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_cleaner(text):\n",
    "    text = re.sub(r'--', ' ', text)\n",
    "    text = re.sub(\"[\\[].*?[\\]]\", \"\", text)\n",
    "    text = re.sub(r'Chapter \\d+', '', text)\n",
    "    text = ' '.join(text.split())\n",
    "    return text[0:900000]\n",
    "\n",
    "austen = \"\"\n",
    "for novel in ['persuasion', 'emma', 'sense']:\n",
    "    work = gutenberg.raw('austen-' + novel + '.txt')\n",
    "    austen += work\n",
    "    \n",
    "austen_clean = text_cleaner(austen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en')\n",
    "austen_doc = nlp(austen_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['lady', 'russell', 'steady', 'age', 'character', 'extremely', 'provide', 'thought', 'second', 'marriage', 'need', 'apology', 'public', 'apt', 'unreasonably', 'discontent', 'woman', 'marry', 'sir', 'walter', 'continue', 'singleness', 'require', 'explanation']\n",
      "We have 9299 sentences and 900000 tokens.\n"
     ]
    }
   ],
   "source": [
    "sentences = []\n",
    "for sentence in austen_doc.sents:\n",
    "    sentence = [\n",
    "        token.lemma_.lower()\n",
    "        for token in sentence\n",
    "        if not token.is_stop\n",
    "        and not token.is_punct\n",
    "    ]\n",
    "    sentences.append(sentence)\n",
    "    \n",
    "print(sentences[20])\n",
    "print('We have {} sentences and {} tokens.'.format(len(sentences), len(austen_clean)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "model = word2vec.Word2Vec(\n",
    "    sentences,\n",
    "    workers=4,     #number of threads to run in parallel\n",
    "    min_count=10,  #minimum word count threshold\n",
    "    window=6,      #number of words around the target to consider\n",
    "    sg=0,          #use CBOW:0, skip-gram:1\n",
    "    sample=1e-3,   #penalize frequent words\n",
    "    size=300,      #word vector length\n",
    "    hs=1           #use hierarchical softmax\n",
    ")\n",
    "\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('musgrove', 0.9526277780532837), ('benwick', 0.946715235710144), ('clay', 0.9406770467758179), ('goddard', 0.9396756291389465), ('wentworth', 0.9253109693527222), ('harville', 0.9202356338500977), ('colonel', 0.8757010698318481), ('hall', 0.8667272925376892), ('smith', 0.8595788478851318), ('weston', 0.8587863445281982)]\n",
      "\n",
      "0.9287651777267456\n",
      "\n",
      "marriage\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:7: DeprecationWarning: Call to deprecated `doesnt_match` (Method will be removed in 4.0.0, use self.wv.doesnt_match() instead).\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "vocab = model.wv.vocab.keys()\n",
    "\n",
    "print(model.wv.most_similar(positive=['lady', 'man'], negative=['woman']))\n",
    "\n",
    "print('\\n{}'.format(model.wv.similarity('mr', 'mrs')))\n",
    "\n",
    "print('\\n{}'.format(model.doesnt_match('breakfast marriage dinner lunch'.split())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n",
      "[('uppercross', 0.8354675769805908), ('anne', 0.8317722082138062), ('heart', 0.8266140222549438), ('course', 0.8171985149383545), ('live', 0.8138149380683899), ('kellynch', 0.8135673999786377), ('acquaintance', 0.7988577485084534), ('listen', 0.7795247435569763), ('call', 0.7785896062850952), ('mary', 0.7690882086753845)]\n",
      "\n",
      "0.7493101358413696\n",
      "\n",
      "dinner\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:20: DeprecationWarning: Call to deprecated `doesnt_match` (Method will be removed in 4.0.0, use self.wv.doesnt_match() instead).\n"
     ]
    }
   ],
   "source": [
    "model = word2vec.Word2Vec(\n",
    "    sentences,\n",
    "    workers=4,     #number of threads to run in parallel\n",
    "    min_count=50,  #minimum word count threshold\n",
    "    window=4,      #number of words around the target to consider\n",
    "    sg=1,          #use CBOW:0, skip-gram:1\n",
    "    sample=1e-3,   #penalize frequent words\n",
    "    size=300,      #word vector length\n",
    "    hs=1           #use hierarchical softmax\n",
    ")\n",
    "\n",
    "print('Done!')\n",
    "\n",
    "vocab = model.wv.vocab.keys()\n",
    "\n",
    "print(model.wv.most_similar(positive=['lady', 'man'], negative=['woman']))\n",
    "\n",
    "print('\\n{}'.format(model.wv.similarity('mr', 'mrs')))\n",
    "\n",
    "print('\\n{}'.format(model.doesnt_match('breakfast marriage dinner lunch'.split())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Changing to skip-gram, decreasing the window, and upping the min count threshold made the model a lot worse than the initial. It also selected the wrong word from the sentence. Let's try going the other way with those parameters and switching back to CBOW."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n",
      "[('benwick', 0.9414724707603455), ('musgrove', 0.9320449829101562), ('harville', 0.9121419191360474), ('charles', 0.9103752374649048), ('goddard', 0.9028724431991577), ('clay', 0.9002286195755005), ('wentworth', 0.8816044330596924), ('conscious', 0.8659206032752991), ('mary', 0.8458876013755798), ('hall', 0.8385883569717407)]\n",
      "\n",
      "0.9557908177375793\n",
      "\n",
      "dinner\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:20: DeprecationWarning: Call to deprecated `doesnt_match` (Method will be removed in 4.0.0, use self.wv.doesnt_match() instead).\n"
     ]
    }
   ],
   "source": [
    "model = word2vec.Word2Vec(\n",
    "    sentences,\n",
    "    workers=4,     #number of threads to run in parallel\n",
    "    min_count=10,  #minimum word count threshold\n",
    "    window=8,      #number of words around the target to consider\n",
    "    sg=0,          #use CBOW:0, skip-gram:1\n",
    "    sample=1e-3,   #penalize frequent words\n",
    "    size=300,      #word vector length\n",
    "    hs=1           #use hierarchical softmax\n",
    ")\n",
    "\n",
    "print('Done!')\n",
    "\n",
    "vocab = model.wv.vocab.keys()\n",
    "\n",
    "print(model.wv.most_similar(positive=['lady', 'man'], negative=['woman']))\n",
    "\n",
    "print('\\n{}'.format(model.wv.similarity('mr', 'mrs')))\n",
    "\n",
    "print('\\n{}'.format(model.doesnt_match('breakfast marriage dinner lunch'.split())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Taking the window up to 8 and the min_count back to 10 shows better similarity with mr. and mrs., but it selected dinner instead of marriage from the list. Also, it chose the word 'mary' from the vocab but it should have chosen male names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n",
      "[('musgrove', 0.96905517578125), ('benwick', 0.9638471603393555), ('goddard', 0.9537417888641357), ('harville', 0.9398235082626343), ('wentworth', 0.9164236783981323), ('clay', 0.9051190614700317), ('colonel', 0.9001761674880981), ('cole', 0.8700426816940308), ('weston', 0.86616051197052), ('consult', 0.8582299947738647)]\n",
      "\n",
      "0.958689272403717\n",
      "\n",
      "marriage\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:20: DeprecationWarning: Call to deprecated `doesnt_match` (Method will be removed in 4.0.0, use self.wv.doesnt_match() instead).\n"
     ]
    }
   ],
   "source": [
    "model = word2vec.Word2Vec(\n",
    "    sentences,\n",
    "    workers=4,     #number of threads to run in parallel\n",
    "    min_count=10,  #minimum word count threshold\n",
    "    window=8,      #number of words around the target to consider\n",
    "    sg=0,          #use CBOW:0, skip-gram:1\n",
    "    sample=1e-3,   #penalize frequent words\n",
    "    size=600,      #word vector length\n",
    "    hs=1           #use hierarchical softmax\n",
    ")\n",
    "\n",
    "print('Done!')\n",
    "\n",
    "vocab = model.wv.vocab.keys()\n",
    "\n",
    "print(model.wv.most_similar(positive=['lady', 'man'], negative=['woman']))\n",
    "\n",
    "print('\\n{}'.format(model.wv.similarity('mr', 'mrs')))\n",
    "\n",
    "print('\\n{}'.format(model.doesnt_match('breakfast marriage dinner lunch'.split())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Increasing the vector length seems to have improved everything. It selected marriage as the non-similar word, the similarity with mr and mrs was higher than the original model and the similar words that mach the analogy all work."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drill 1: word2vec on 100B+ words\n",
    "\n",
    "Due to previous issues with memory I am going to look at the Google News Model that is a web app.\n",
    "https://rare-technologies.com/word2vec-tutorial/#bonus_app"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tried kid : messy :: adult:? and got back messier, chaotic, & unpleasant. Does that mean that kids get it from their parents?\n",
    "\n",
    "when looking for the most similar words to vicarious, the model returned 'escapist fantasy'.\n",
    "\n",
    "Trying to remove the word that did not belong from the following list: balloon party confetti shovel cake presents resulted in the word presents. I think in this case it had trouble with the word presents having a double meaning.\n",
    "\n",
    "Last thing I tried was gibberish. I put blue red iuerb green purple black into the box to choose the phrase that doesn't exist. Everytime the model selected one of the colors instead of luerb. I put that gibberish into the box to find the most similar and got nothing back. Since the word2vec model is built with thresholds on how often a word is found, then it will likely give gibberish words or misspellings no vector value at all and therefore can't be compared to the rest of the words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
