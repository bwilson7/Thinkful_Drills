{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "6.8.4_challenge_sentiment_analysis.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bwilson7/thinkful_drills/blob/master/6_8_4_challenge_sentiment_analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CbLsTVK_FIot",
        "colab_type": "text"
      },
      "source": [
        "# Toy & Game Sentiment Reviews\n",
        "\n",
        "For this sentiment analysis I wanted to look at Amazon reviews of toys and games. In total there are ~167k reviews in the dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0FvYjhSZj4_a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "!wget -q http://apache.osuosl.org/spark/spark-2.4.4/spark-2.4.4-bin-hadoop2.7.tgz\n",
        "!tar xf spark-2.4.4-bin-hadoop2.7.tgz"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n6UnL7Goj8nT",
        "colab_type": "code",
        "outputId": "ef5589ea-7230-4eed-b046-1a8865399492",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 258
        }
      },
      "source": [
        "# Install spark-related depdencies for Python\n",
        "!pip install -q findspark\n",
        "!pip install pyspark"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pyspark\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/87/21/f05c186f4ddb01d15d0ddc36ef4b7e3cedbeb6412274a41f26b55a650ee5/pyspark-2.4.4.tar.gz (215.7MB)\n",
            "\u001b[K     |████████████████████████████████| 215.7MB 1.2MB/s \n",
            "\u001b[?25hCollecting py4j==0.10.7 (from pyspark)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e3/53/c737818eb9a7dc32a7cd4f1396e787bd94200c3997c72c1dbe028587bd76/py4j-0.10.7-py2.py3-none-any.whl (197kB)\n",
            "\u001b[K     |████████████████████████████████| 204kB 47.6MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-2.4.4-py2.py3-none-any.whl size=216130387 sha256=8cd806116cc609dc31fdc028925f2181076d97333475c7ddd4558e6dc801fc46\n",
            "  Stored in directory: /root/.cache/pip/wheels/ab/09/4d/0d184230058e654eb1b04467dbc1292f00eaa186544604b471\n",
            "Successfully built pyspark\n",
            "Installing collected packages: py4j, pyspark\n",
            "Successfully installed py4j-0.10.7 pyspark-2.4.4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k7BCHfMzgUV8",
        "colab_type": "code",
        "outputId": "01a446c6-8f32-410e-c985-7e013c36e390",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "!pip install nltk"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.6/dist-packages (3.2.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from nltk) (1.12.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2XHp4bVUj-vI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Set up required environment variables\n",
        "\n",
        "import os\n",
        "\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-2.4.4-bin-hadoop2.7\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HfUs-ksp86AL",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DJNmE9LS87Rv",
        "colab_type": "text"
      },
      "source": [
        "# Module Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qAK8Xd03C6zB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pyspark import SparkContext\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "from pyspark.ml import Pipeline\n",
        "from pyspark.ml.classification import RandomForestClassifier, RandomForestClassificationModel, LogisticRegression\n",
        "from pyspark.ml.feature import IndexToString, StringIndexer, VectorIndexer, VectorAssembler, Tokenizer, StopWordsRemover, CountVectorizer\n",
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator, BinaryClassificationEvaluator\n",
        "from pyspark.mllib.evaluation import MulticlassMetrics\n",
        "\n",
        "from pyspark.sql.functions import isnan, when, count, col, split, collect_set, lit\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import seaborn as sns\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5JUc4QChcSLV",
        "colab_type": "code",
        "outputId": "0aea1df5-94ff-4c29-f68a-bb041dff9ba7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        " nltk.download('stopwords')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IPIXA8ESG4Op",
        "colab_type": "code",
        "outputId": "9b0ec52c-b37b-4d8f-d4e6-d0d64e10bb03",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QFBdK_uKkOnJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "DATA_PATH = \"/content/gdrive/My Drive/colab_datasets/reviews_Toys_and_Games_5.json\"\n",
        "APP_NAME = 'amazon_sentiment_analysis'\n",
        "SPARK_URL = 'local[*]'\n",
        "\n",
        "spark = SparkSession.builder.appName(APP_NAME).master(SPARK_URL).getOrCreate()\n",
        "df = spark.read.options(inferschema = \"true\").json(DATA_PATH)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FcEL0HvYnLWB",
        "colab_type": "code",
        "outputId": "185498f8-d016-4fee-f7b0-640b9c196e14",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        }
      },
      "source": [
        "df.show(5)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+----------+-------+-------+--------------------+-----------+--------------+--------------+--------------------+--------------+----------+\n",
            "|      asin|helpful|overall|          reviewText| reviewTime|    reviewerID|  reviewerName|             summary|unixReviewTime|isPositive|\n",
            "+----------+-------+-------+--------------------+-----------+--------------+--------------+--------------------+--------------+----------+\n",
            "|0439893577| [0, 0]|    5.0|I like the item p...|01 29, 2014|A1VXOAVRGKGEAK|         Angie|      Magnetic board|    1390953600|         1|\n",
            "|0439893577| [1, 1]|    4.0|Love the magnet e...|03 28, 2014| A8R62G708TSCM|       Candace|it works pretty g...|    1395964800|         1|\n",
            "|0439893577| [1, 1]|    5.0|Both sides are ma...|01 28, 2013|A21KH420DK0ICA|capemaychristy|          love this!|    1359331200|         1|\n",
            "|0439893577| [0, 0]|    5.0|Bought one a few ...| 02 8, 2014| AR29QK6HPFYZ4|          dcrm|   Daughters love it|    1391817600|         1|\n",
            "|0439893577| [1, 1]|    4.0|I have a stainles...| 05 5, 2014| ACCH8EOML6FN5|          DoyZ|Great to have so ...|    1399248000|         1|\n",
            "+----------+-------+-------+--------------------+-----------+--------------+--------------+--------------------+--------------+----------+\n",
            "only showing top 5 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NCevLLc4bkCg",
        "colab_type": "code",
        "outputId": "b5fc66fc-a7c3-44f3-fcfc-3f4538c0175a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "#adding sentiment column and column of arrays for each string\n",
        "df = df.withColumn('isPositive', when(df.overall >=3, 1.0).otherwise(0.0))\n",
        "#df = df.withColumn('reviewArray', split(df['reviewText'], '\\s+'))\n",
        "df.groupby('isPositive').count().show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+----------+------+\n",
            "|isPositive| count|\n",
            "+----------+------+\n",
            "|       0.0| 11005|\n",
            "|       1.0|156592|\n",
            "+----------+------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "msta8aK6sZPF",
        "colab_type": "text"
      },
      "source": [
        "The isPositive column is working and filling in a positive or negative based on the overall rating, but there is a small problem with class imbalance. Currently our negative review class is sitting at ~6% of the dataset. I'll use the logistic regression package since it has a built in column weights parameter that I can tune. For this I need to calcualte a balancing ratio based on the number of positive and negative results and the total dataset size. This step will be done on the training set, since the test set will have an \"unknown\" amount of class imbalance. Theoretically, the imbalance should be the same from training to test."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tjpXIBWrbXYF",
        "colab_type": "text"
      },
      "source": [
        "# Testing Pipeline Transformers\n",
        "\n",
        "Below I am testing the different transformers outputs so that I know the features column will be what I expect."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_GO08LBIbK3s",
        "colab_type": "code",
        "outputId": "ae952760-dd31-4de1-d5ae-5963e6043679",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "#checking the tokenizer transformer works, it also lowercases everything\n",
        "tokenizer = Tokenizer(inputCol='reviewText', outputCol='reviewToken')\n",
        "df = tokenizer.transform(df)\n",
        "df.select('reviewText', 'reviewToken').show(5)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+--------------------+--------------------+\n",
            "|          reviewText|         reviewToken|\n",
            "+--------------------+--------------------+\n",
            "|I like the item p...|[i, like, the, it...|\n",
            "|Love the magnet e...|[love, the, magne...|\n",
            "|Both sides are ma...|[both, sides, are...|\n",
            "|Bought one a few ...|[bought, one, a, ...|\n",
            "|I have a stainles...|[i, have, a, stai...|\n",
            "+--------------------+--------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zp2RARCmbK58",
        "colab_type": "code",
        "outputId": "e1703b5f-bf04-41c1-ba6d-f55b1114cfe9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "# taking the tokened reviews and removing stop words\n",
        "# next step will be to check term frequencies for each review\n",
        "stopWords = stopwords.words('english')\n",
        "remover = StopWordsRemover(inputCol='reviewToken', outputCol='reviewToken_stop', stopWords=stopWords)\n",
        "\n",
        "df = remover.transform(df)\n",
        "df.select('reviewText', 'reviewToken', 'reviewToken_stop').show(5)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+--------------------+--------------------+--------------------+\n",
            "|          reviewText|         reviewToken|    reviewToken_stop|\n",
            "+--------------------+--------------------+--------------------+\n",
            "|I like the item p...|[i, like, the, it...|[like, item, pric...|\n",
            "|Love the magnet e...|[love, the, magne...|[love, magnet, ea...|\n",
            "|Both sides are ma...|[both, sides, are...|[sides, magnetic....|\n",
            "|Bought one a few ...|[bought, one, a, ...|[bought, one, yea...|\n",
            "|I have a stainles...|[i, have, a, stai...|[stainless, steel...|\n",
            "+--------------------+--------------------+--------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IbtpgalvbK-b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#collecting all of the common words in the reviews\n",
        "common_words = df.freqItems(['reviewToken_stop']).collect()   "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vLyS80kS0VeH",
        "colab_type": "code",
        "outputId": "fa29a56b-3124-4bf7-fba4-0ab4dd702e2a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#combining them into a set for generation of columns of features\n",
        "common = []\n",
        "for words in common_words[0][0]:\n",
        "    common += words\n",
        "len(set(common))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1236"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7fel8N4H0VgK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cv = CountVectorizer(inputCol='reviewToken_stop', outputCol='reviewVector')\n",
        "model = cv.fit(df)\n",
        "df = model.transform(df)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g5AY8ovHZbIU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#splitting review into tokens\n",
        "tokenizer = Tokenizer(inputCol='reviewText', outputCol='reviewToken')\n",
        "\n",
        "#removing stopwords from tokened reviews\n",
        "stopWords = stopwords.words('english')\n",
        "remover = StopWordsRemover(inputCol='reviewToken', outputCol='reviewToken_stop', stopWords=stopWords)\n",
        "\n",
        "#sparse vectors that count valuesof each vocab word\n",
        "cv = CountVectorizer(inputCol='reviewToken_stop', outputCol='featureVector')\n",
        "\n",
        "(trainingData, testData) = df.randomSplit([0.75, 0.25])\n",
        "\n",
        "#rf classifier\n",
        "lr = LogisticRegression(featuresCol='featureVector', labelCol='isPositive', weightCol='classWeights')\n",
        "\n",
        "pipeline = Pipeline(stages=[tokenizer, remover, cv, lr])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kate0lSnKRsh",
        "colab_type": "code",
        "outputId": "dc9be5f3-5537-48ed-aa3e-1698e2222447",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "numPosTrain = trainingData.select('isPositive').where('isPositive == 1.0').count()\n",
        "numNegTrain = trainingData.select('isPositive').where('isPositive == 0.0').count()\n",
        "print('Training Size = {}'.format(numPosTrain + numNegTrain))\n",
        "print('Number of Positive Reviews = {}'.format(numPosTrain))\n",
        "print('Number of Negative Reviews = {}'.format(numNegTrain))\n",
        "print('Minority Class Balancing Ratio = {}'.format(numPosTrain / (numPosTrain + numNegTrain)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training Size = 125898\n",
            "Number of Positive Reviews = 117668\n",
            "Number of Negative Reviews = 8230\n",
            "Minority Class Balancing Ratio = 0.934629620804143\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FffbxpQFLwOk",
        "colab_type": "text"
      },
      "source": [
        "Ok, so the negative reviews will get a calss balance of 0.9346... and the positive reviews will get a class balance of 1 - 0.9346..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "btSoF_caL6vY",
        "colab_type": "code",
        "outputId": "f006db54-01a5-4e1a-b562-0a3ae544c155",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "classBalanceRatio = numPosTrain / (numPosTrain + numNegTrain)\n",
        "trainingData = trainingData.withColumn('classWeights', when(trainingData.isPositive == 0.0, classBalanceRatio).otherwise(1-classBalanceRatio))\n",
        "trainingData.groupby('classWeights').count().show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-------------------+------+\n",
            "|       classWeights| count|\n",
            "+-------------------+------+\n",
            "|0.06537037919585698|117668|\n",
            "|  0.934629620804143|  8230|\n",
            "+-------------------+------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4vmnTIu2cabH",
        "colab_type": "text"
      },
      "source": [
        "Looks like all of the class weights were input corectly into the trainingData df. Hopefully this will help with classification issues that were seen when running a RandomForestClassifier without any sort of class balance considerations (Model only predicts positive result since negative is so uncommon)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nwX1h_GKsDBF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = pipeline.fit(trainingData)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wYl3M7eBsOel",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predictions = model.transform(testData)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C0LLEpInszfR",
        "colab_type": "code",
        "outputId": "fa10eaad-3244-4434-d4c4-525468d08ae0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "# Select (prediction, true label) and compute test error\n",
        "evaluator = MulticlassClassificationEvaluator(\n",
        "    labelCol=\"isPositive\", predictionCol=\"prediction\", metricName='weightedPrecision')\n",
        "\n",
        "print('Precision:', evaluator.evaluate(predictions))\n",
        "\n",
        "recall = evaluator.evaluate(predictions, {evaluator.metricName:'weightedRecall'})\n",
        "print('Recall:', recall)\n",
        "\n",
        "f1 = evaluator.evaluate(predictions, {evaluator.metricName:'f1'})\n",
        "print('Recall:', f1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Precision: 0.920552393779295\n",
            "Recall: 0.9170723518549606\n",
            "Recall: 0.9187512002462199\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kqr5BIYAEe-q",
        "colab_type": "code",
        "outputId": "002e6c35-6e30-4ceb-ca88-484fb6ff405b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "conf_matrix = predictions.crosstab('isPositive', 'prediction')\n",
        "conf_matrix.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+---------------------+----+-----+\n",
            "|isPositive_prediction| 0.0|  1.0|\n",
            "+---------------------+----+-----+\n",
            "|                  1.0|1856|37068|\n",
            "|                  0.0|1173| 1602|\n",
            "+---------------------+----+-----+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wlbn_X-kBM_G",
        "colab_type": "code",
        "outputId": "538d1efa-97b3-400e-9a9b-90b7e8455762",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        }
      },
      "source": [
        "predictions.groupby('isPositive').count().show()\n",
        "predictions.groupby('prediction').count().show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+----------+-----+\n",
            "|isPositive|count|\n",
            "+----------+-----+\n",
            "|       0.0| 2775|\n",
            "|       1.0|38924|\n",
            "+----------+-----+\n",
            "\n",
            "+----------+-----+\n",
            "|prediction|count|\n",
            "+----------+-----+\n",
            "|       0.0| 3029|\n",
            "|       1.0|38670|\n",
            "+----------+-----+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mbXup7peIgb5",
        "colab_type": "text"
      },
      "source": [
        "Not too bad without any hyperparameter tuning. The amount of false positives and false negatives were similar, but the minority class is still has a lot of error. Precision and recall are high for positive reviews, but the negative review predictions are still quite low."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gs70lCn9szbV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qVI7HEF_szYb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m64qB49pszV0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZTOE3iQkszSK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "obvmjwY7bLAj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "clSRlFkZbLDB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Q2DS3Q9bLFQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4qxkLV3xFr9X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}